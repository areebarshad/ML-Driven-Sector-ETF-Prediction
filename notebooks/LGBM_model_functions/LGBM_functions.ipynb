{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmVvYU8496czaiFTU5OW8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areebarshad/sp500-sector-prediction/blob/main/notebooks/LGBM_model_functions/LGBM_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6b2hfqGYyKm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#define a feature engineering function for the sector pipeline\n",
        "def generate_features(returns, target_ticker, tickers, rolling_window = 10, n_pca = 5):\n",
        "\n",
        "  lagged_returns = returns.shift(1)\n",
        "  features = pd.DataFrame(index = returns.index)\n",
        "\n",
        "  #add basic statistical features\n",
        "  features[f'{target_ticker}_mean'] = lagged_returns[target_ticker].rolling(rolling_window).mean()\n",
        "  features[f'{target_ticker}_vol'] = lagged_returns[target_ticker].rolling(rolling_window).std()\n",
        "  features[f'{target_ticker}_skew'] = lagged_returns[target_ticker].rolling(rolling_window).skew()\n",
        "  features[f'{target_ticker}_kurt'] = lagged_returns[target_ticker].rolling(rolling_window).kurt()\n",
        "  features[f'{target_ticker}_momentum'] = lagged_returns[target_ticker] - lagged_returns[target_ticker].rolling(rolling_window).mean()\n",
        "  features[f'{target_ticker}_momentum_ratio'] = features[f'{target_ticker}_momentum'] / (features[f'{target_ticker}_vol'] + 1e-6)\n",
        "\n",
        "  #compress redudant lag features using PCA\n",
        "  lags = pd.DataFrame({f'lag_{i}': returns[target_ticker].shift(i) for i in range(1,11)}).dropna()\n",
        "  pca = PCA(n_components = 5)\n",
        "  lagged_pca = pd.DataFrame(pca.fit_transform(lags), index = lags.index)\n",
        "  lagged_pca.columns = [f'lag_pca_{i}' for i in range(lagged_pca.shape[1])]\n",
        "  features = features.join(lagged_pca)\n",
        "\n",
        "  #add technical indicators\n",
        "  features[f'{target_ticker}_rolling_mean_10'] = returns[target_ticker].rolling(10).mean()\n",
        "  features[f'{target_ticker}_rolling_std_10'] = returns[target_ticker].rolling(10).std()\n",
        "  features[f'{target_ticker}_volatility_ratio'] = features[f'{target_ticker}_rolling_std_10'] / (features[f'{target_ticker}_rolling_mean_10'] + 1e-6)\n",
        "\n",
        "  #use SPY correlation and covariance\n",
        "  features[f'{target_ticker}_corr'] = returns[target_ticker].rolling(10).corr(returns['SPY'])\n",
        "  features[f'{target_ticker}_cov'] = returns[target_ticker].rolling(10).cov(returns['SPY'])\n",
        "\n",
        "  #add trend and volatility features\n",
        "  features[f'{target_ticker}_cumulative_return'] = returns[target_ticker].rolling(20).apply(np.sum)\n",
        "  features[f'{target_ticker}_max_drawdown'] = (\n",
        "      returns[target_ticker].rolling(20).apply(lambda x: np.min(x / (np.maximum.accumulate(x + 1e-6)) - 1)))\n",
        "\n",
        "  #feature enhancment: sector wide momentum\n",
        "  features['sector_momentum'] = returns.drop(columns = [target_ticker]).mean(axis = 1).shift(1)\n",
        "  features['sector_volatility'] = returns.drop(columns = [target_ticker]).std(axis = 1).shift(1)\n",
        "  features['sector_sharpe'] = features['sector_momentum'] / (features['sector_volatility'] + 1e-6)\n",
        "\n",
        "  #add temporal regularization\n",
        "  features[f'{target_ticker}_ewm_mean'] = returns[target_ticker].ewm(span = 10).mean().shift(1)\n",
        "  features[f'{target_ticker}_ewm_std'] = returns[target_ticker].ewm(span = 10).std().shift(1)\n",
        "\n",
        "  #implement VIX and TNX [macroeconomic indicators (volatility and rates)]\n",
        "  vix_raw = yf.download(\"^VIX\", start = \"2008-01-01\", end = \"2025-12-31\")['Close']\n",
        "  tnx_raw = yf.download(\"^TNX\", start = \"2008-01-01\", end = \"2025-12-31\")['Close']\n",
        "\n",
        "  vix_znorm = (vix_raw - vix_raw.rolling(60).mean()) / (vix_raw.rolling(60).std() + 1e-6)\n",
        "  tnx_znorm = (tnx_raw - tnx_raw.rolling(60).mean()) / (tnx_raw.rolling(60).std() + 1e-6)\n",
        "  features['vix_zscore'] = vix_znorm.shift(1)\n",
        "  features['tnx_zscore'] = tnx_znorm.shift(1)\n",
        "\n",
        "  #implement a volatility regime switch\n",
        "  features['market_vol_regime'] = (features['vix_zscore'] > 1).astype(int)\n",
        "\n",
        "  #add lagged macros\n",
        "  for lag in range(1, 6):\n",
        "      features[f'vix_zscore_lag{lag}'] = features['vix_zscore'].shift(lag)\n",
        "      features[f'tnx_zscore_lag{lag}'] = features['tnx_zscore'].shift(lag)\n",
        "\n",
        "  #add interaction feature\n",
        "  for lag in range(1, 6):\n",
        "      features[f'{target_ticker}_lag{lag}_momentum'] = returns[target_ticker].shift(lag) - returns[target_ticker].shift(lag+5)\n",
        "      features[f'{target_ticker}_lag{lag}_mom_vol'] = (\n",
        "          features[f'{target_ticker}_lag{lag}_momentum'] * features[f'{target_ticker}_vol'])\n",
        "\n",
        "  #add rolling beta and market deviation\n",
        "  features[f'{target_ticker}_rolling_beta'] = (\n",
        "      returns[target_ticker].rolling(20).cov(returns['SPY']) /\n",
        "      returns['SPY'].rolling(20).var()\n",
        "  ).shift(1)\n",
        "\n",
        "  features[f'{target_ticker}_market_dev'] = (\n",
        "      returns[target_ticker] - returns['SPY']\n",
        "  ).rolling(7).mean().shift(1)\n",
        "\n",
        "  #add sector interaction signals (correlation with other signals)\n",
        "  for other in tickers:\n",
        "      if other != target_ticker:\n",
        "          features[f'{target_ticker}_{other}_corr'] = (\n",
        "              returns[target_ticker].rolling(15).corr(returns[other]))\n",
        "\n",
        "  features[f'{target_ticker}_returns_1d'] = returns[target_ticker].shift(1)\n",
        "\n",
        "  #add time based features\n",
        "  features['month'] = features.index.month\n",
        "  features['week_of_year'] = features.index.isocalendar().week.astype(int)\n",
        "  features['day_of_week'] = features.index.dayofweek\n",
        "  features['is_month_start'] = features.index.is_month_start.astype(int)\n",
        "  features['is_month_end'] = features.index.is_month_end.astype(int)\n",
        "\n",
        "  return features.dropna()\n",
        "\n",
        "#create a function for the training and evaluating of model\n",
        "def train_evaluate_model(features, target, target_ticker, sector_params, verbose = False):\n",
        "  target = target.dropna()\n",
        "  features = features.dropna()\n",
        "  common_index = features.index.intersection(target.index)\n",
        "  X = features.loc[common_index]\n",
        "  y = target.loc[common_index]\n",
        "\n",
        "  #drop multicollinear features\n",
        "  corr_matrix = X.corr().abs()\n",
        "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=  1).astype(bool))\n",
        "  to_drop = [columns for columns in upper.columns if any(upper[columns] > 0.95)]\n",
        "  X = X.drop(columns = to_drop)\n",
        "\n",
        "  #add a dummy variable\n",
        "  sector_dummies = pd.get_dummies([target_ticker] * len(X), prefix = 'sector')\n",
        "  features = pd.concat([features, pd.DataFrame(sector_dummies.values,\n",
        "                                               index = X.index, columns = sector_dummies.columns)], axis = 1)\n",
        "\n",
        "  #scale the features\n",
        "  scaler = StandardScaler()\n",
        "  X_scaled = pd.DataFrame(scaler.fit_transform(X), index = X.index, columns = X.columns)\n",
        "\n",
        "  #train, test split with OOT sample\n",
        "  X_train = X_scaled.loc['2010-01-01':'2020-12-31']\n",
        "  X_test = X_scaled.loc['2021-01-01':'2025-12-31']\n",
        "  y_train = y.loc['2010-01-01':'2020-12-31']\n",
        "  y_test = y.loc['2021-01-01':'2025-12-31']\n",
        "\n",
        "  #initialize and fit the model\n",
        "  params = sector_params.get(target_ticker, {\"max_depth\": 10, \"num_leaves\": 64})\n",
        "  model = LGBMRegressor(n_estimators = 1000, learning_rate = 0.01, verbose = -1,\n",
        "                        subsample = 0.8, colsample_bytree = 0.8, reg_alpha = 0.05,\n",
        "                        reg_lambda = 0.5, random_state = 42, **params)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  #predict\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  #drop noise with feature importance\n",
        "  importances_df = pd.DataFrame({'Feature': X_scaled.columns, 'Importance': model.feature_importances_})\n",
        "  important_feats = importances_df[importances_df['Importance'] > np.percentile(importances_df['Importance'], 65)]\n",
        "  X_scaled_top = X_scaled[important_feats['Feature']]\n",
        "\n",
        "  #re-evaluate using top features\n",
        "  X_train_P = X_scaled_top.loc['2010-01-01':'2020-12-31']\n",
        "  X_test_P = X_scaled_top.loc['2021-01-01':'2025-12-31']\n",
        "  y_train = y.loc['2010-01-01':'2020-12-31']\n",
        "  y_test = y.loc['2021-01-01':'2025-12-31']\n",
        "\n",
        "  #fit model again\n",
        "  model.fit(X_train_P, y_train)\n",
        "\n",
        "  #predict again\n",
        "  y_pred = model.predict(X_test_P)\n",
        "\n",
        "  #compute the evaluation metrics\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "  rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "  print(f\"LightGBM -> R^2: {r2:.4f}, RMSE: {rmse:.6f}, MAE: {mae:.6f}\")\n",
        "\n",
        "  return {\n",
        "        'model': model,\n",
        "        'r2': r2,\n",
        "        'rmse': rmse,\n",
        "        'mae': mae,\n",
        "        'y_test': y_test,\n",
        "        'y_pred': pd.Series(y_pred, index = y_test.index),\n",
        "        'X_test': X_test\n",
        "        'importances_df': importances_df\n",
        "    }\n",
        "\n",
        "#create a function to plot feature importances\n",
        "def plot_feature_importances(importances_df, target_ticker):\n",
        "\n",
        "  #sort by importance and keep only the top 20 features\n",
        "  top_feats = importances_df.sort_values(by = 'Importance', ascending = False).head(20)\n",
        "  plt.figure(figsize = (10, 6))\n",
        "  plt.barh(top_feats['Feature'], top_feats['Importance'], color = 'teal')\n",
        "  plt.title(f'Top 20 Feature Importances: {target_ticker}')\n",
        "  plt.xlabel('Importance')\n",
        "  plt.ylabel('Features')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "#create a function to plot the predicted VS actual\n",
        "def plot_actual_vs_predicted(y_test, y_pred, target_ticker, title_note = \"\"):\n",
        "    plt.figure(figsize = (12, 6))\n",
        "    plt.plot(y_test.index, y_test.values, label = 'Actual', color = 'crimson', alpha = 0.7, linewidth = 2)\n",
        "    plt.plot(y_test.index, y_pred.values, label = 'Predicted', color = 'royal blue', alpha = 0.7, linewidth = 2)\n",
        "    plt.title(f'{target_ticker} - LightGBM Predicted Returns', fontsize = 14)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Returns')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    }
  ]
}